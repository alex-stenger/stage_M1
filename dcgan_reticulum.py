# -*- coding: utf-8 -*-
"""gan_reticulum_bin.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gVf4KXPwH7CvOBztivV50lUXkjKvZCAH
"""

from __future__ import print_function
#%matplotlib inline
import argparse
import os
import random
import imageio
import time
import torch
import torch.nn as nn
import torch.nn.parallel
import torch.backends.cudnn as cudnn
import torch.optim as optim
import torch.utils.data
import torchvision.datasets as dset
import torchvision.transforms as transforms
import torchvision.utils as vutils
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation as animation
from IPython.display import HTML
from torch.autograd import Variable


ngpu = 1

device = torch.device("cuda:0" if (torch.cuda.is_available() and ngpu > 0) else "cpu")

#dataroot = "data/dilat_sorted_disk_10/dilat/"  #reticulum contourés texturés dilatés disk(10)

dataroot = "data/pandley_mask/rec"                #reticulum contouré binarisé (masque binaire)

#dataroot = "data/croped_patch_full/text"                  #reticulum non contouré texturés

#dataroot = "data/croped_texture_contour/cont"          #reticulum contourés texturés

img_mult = 1 #ATTENTION TRES IMPORTANT
             #Dans le papier original, le Generateur et Discri sont fait pour traiter des img de taille 64*64.
             #On indroduit la variable img_mult pour les adapter et traiter des images de tailles différentes (multiples de 64)

image_size = 64 * img_mult #voir si on met autre chose ?

batch_size = 128 

workers = 2

ngpu = 1

nz = 100

# Attention, on est sur du noir et blanc, donc je suppose 1 seul cannal de couleur
nc = 1



ngf = 64 #(ou 128 peut-être) #Si j'ai bien compris, c'est pour donner la taille de ce que l'on souhaite générer
ndf = 64 #(ou 128 peut-être)

num_epoch = 100

dataset = dset.ImageFolder(root=dataroot,
                           transform=transforms.Compose([
                               transforms.Grayscale(num_output_channels=1),  #on passe en nuances de gris !
                               transforms.Resize(image_size),
                               transforms.CenterCrop(image_size),
                               transforms.ToTensor(),
                               transforms.Normalize((0.5), (0.5)),  #Attention, on change ici parce qu'on est passé en grayscale
                           ]))

dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=workers)

# Decide which device we want to run on
device = torch.device("cuda:0" if (torch.cuda.is_available() and ngpu > 0) else "cpu")

# Plot some training images
real_batch = next(iter(dataloader))
print(real_batch[0][0].size())
#print(real_batch[0])
plt.figure(figsize=(14,14))
plt.axis("off")
plt.title("Training Images")
plt.gray()
plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))
#plt.imshow(real_batch[0][0][0])
plt.show()

# Initialisation des poids : les paramètres sont ceux conseillés dans le papier de Goodfellow

def weights_init(m):
    classname = m.__class__.__name__
    if classname.find('Conv') != -1:
        nn.init.normal_(m.weight.data, 0.0, 0.02)
    elif classname.find('BatchNorm') != -1:
        nn.init.normal_(m.weight.data, 1.0, 0.02)
        nn.init.constant_(m.bias.data, 0)

class Generator(nn.Module):
    def __init__(self, ngpu):
        super(Generator, self).__init__()
        self.ngpu = ngpu
        self.main = nn.Sequential(
            # input is Z, going into a convolution
            nn.ConvTranspose2d( nz, ngf * 8 * img_mult, 4, 1, 0, bias=False),
            nn.BatchNorm2d(ngf * 8 * img_mult),
            nn.ReLU(True),
            # state size. (ngf*8) x 4 x 4
            nn.ConvTranspose2d(ngf * 8 * img_mult, ngf * 4 * img_mult, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 4 * img_mult ),
            nn.ReLU(True),
            # state size. (ngf*4) x 8 x 8
            nn.ConvTranspose2d( ngf * 4 * img_mult, ngf * 2 * img_mult, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 2 * img_mult),
            nn.ReLU(True),
            # state size. (ngf*2) x 16 x 16
            nn.ConvTranspose2d( ngf * 2 * img_mult, ngf * img_mult, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * img_mult),
            nn.ReLU(True),
            # state size. (ngf) x 32 x 32
            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),
            nn.Tanh()
            # state size. (nc) x 64 x 64
        )

    def forward(self, input):
        return self.main(input)


class Discriminator(nn.Module):
    def __init__(self, ngpu):
        super(Discriminator, self).__init__()
        self.ngpu = ngpu
        self.main = nn.Sequential(
            # input is (nc) x 64 x 64
            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf) x 32 x 32
            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 2),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf*2) x 16 x 16
            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 4),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf*4) x 8 x 8
            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 8),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf*8) x 4 x 4
            nn.Conv2d(ndf * 8 * img_mult, 1, 4, 1, 0, bias=False),
            nn.Sigmoid()
            #state size. 1
        )

    def forward(self, input):
        return self.main(input)

G = Generator(1).to(device) #pour le faire tourner sur le GPU
D = Discriminator(1).to(device) #de même

G.apply(weights_init)
D.apply(weights_init)

print(G)
print(D)

BCE_loss = nn.BCELoss()

learning_rate = 0.0002
beta1 = 0.5

G_optimizer = optim.Adam(G.parameters(), lr=learning_rate, betas=(beta1, 0.999))
D_optimizer = optim.Adam(D.parameters(), lr=learning_rate, betas=(beta1, 0.999))

real_label = 1
fake_label = 0 

G_loss_l = []
D_loss_l = []

print("Starting Training Loop...")

compteur = 0



noise_for_print = torch.randn(batch_size, nz, 1, 1, device=device)

for epoch in range(num_epoch) :
  for i, data in enumerate(dataloader, 0):  #enumerate retourne une liste d'énumérations, exemple :
                                            #seasons = ['Spring', 'Summer', 'Fall', 'Winter']
                                            #list(enumerate(seasons))
                                            #[(0, 'Spring'), (1, 'Summer'), (2, 'Fall'), (3, 'Winter')]

  #--------------------On commence par améliorer le Discriminateur (maximize log(D(x)) + log(1 - D(G(z))))----------------------

  #D'abbord avec les vraies données
    D.zero_grad()
    real = data[0].to(device)  #on prends la donnée et on la met sur le GPU

    #!!!! REAL A 3 CHANNELS MAIS ON EN VEUX QU'UN

    b_size = real.size(0) 
    label = torch.full((b_size,), real_label, dtype=torch.float, device=device)  #créé un tenseur de taille batch_size contenant les lables (ici real)  (b_size normalement)

    ##print(real.size())

    outputD_real = D(real).view(-1) #La on fait passé les vraies données dans le discriminateur qui va nous renvoyer une proba entre 0 et 1 (proche de 1 vrai, sinon fake)

    #print("output_d : ", outputD_real[0].size())
    #print("label : ", label.size())

    loss_D_real = BCE_loss(outputD_real, label)  #Ok donc là les labels nous permettent de calculer la loss fonction de "D_real"

    loss_D_real.backward() #calcul du gradient  (je ne comprends pas ce qu'on en fait ensuite ?)
    D_x = outputD_real.mean().item ()

    #Ensuite avec les fausses données du générateur (pour avoir la loss fonction complète de D)

    #mini_batch = data[0].size()[0]
    #noise = torch.randn((mini_batch, 100)).view(-1, 100, 1, 1)
    #noise = Variable(noise.cuda())
    
    noise_2 = torch.randn(b_size, nz, 1, 1, device=device) #on génère un vecteur de l'espace latent sur lequel le générateur va travailler
                                                        #Au final, si j'ai bien compris, il va y avoir b_size vecteur de taille z (d'où l'utilité du tenseur)
    if epoch%5==0 and i == 0:
      noise = noise_for_print  #En gros, permet de voir si en donnant le même bruit, ça va nous donner des choses comparables et similaires ??
    else :
      noise = noise_2


    fake = G(noise) #On fait passer le bruit dans le générateur pour qu'il nous sorte un chiffre fake
    label.fill_(fake_label) #Je pense qu'on remplace tout les real_label par des fake_label dans le tenseur qui contient les labels

    outputD_fake = D(fake.detach()).view(-1)  #Je ne comprends pas encore très bien à quoi sert la méthode detach(), sûrement un truc lié aux tenseurs et à leur stockage ?
    
    loss_D_fake = BCE_loss(outputD_fake, label)
    loss_D_fake.backward()

    D_G_z1 = outputD_fake.mean().item()

    loss_D = loss_D_real + loss_D_fake  #Calcul de la loss function "globale" de D

    D_optimizer.step()  #On améliore D




    #-----------------Puis on améliore le Générateur (maximize log(D(G(z))))----------------------------

    G.zero_grad() #"In PyTorch, we need to set the gradients to zero before starting to do backpropragation 
          #because PyTorch accumulates the gradients on subsequent backward passes. Because of this, when you start 
          #your training loop, ideally you should zero out the gradients."

    label.fill_(real_label) #Du point de vue de la loss function du générateur, on a des vrais labels

    outputD2 = D(fake).view(-1)  #.view(-1) permet de renvoyer un tenseur mais "applatit", en gros un tenseur de taille n*1 (?)

    loss_G = BCE_loss(outputD2, label)  #Loss function de G

    loss_G.backward()

    D_G_z2 = outputD2.mean().item()  #.mean() nous donne la moyenne et .item() permet de convertir le tenseur en un réel standard
                                  # Juste ici, il me semble que dans output, il n'y a qu'une seule valeur, donc je ne comprends pas le .mean()

    G_optimizer.step()  #on améliore G

            #Faut vraiment voir ça en 5 étapes :
          #   1) On regarde ce que le discriminateur nous dis sur un fake du generator (la proba qu'il sort) en gros
          #   2) ON calcule la loss fonction (qu'on veut optimiser)
          #   3) Calcul du gradient de la loss function de G (mais je sais pas ce qu'on en fait ensuite)
          #   4) Ennsuite, on calcule D(G(z))
          #   5) On utilie l'optimizer pour update le générateur


    #NOTE : ce qui va nous intéresser (pour l'affichage), c'est l'output de G(noise), c'est à dire "fake"


    G_loss_l.append(loss_G.item())
    D_loss_l.append(loss_D.item())

    if i%50==0 :
      print("iteration ", i+1, "/", len(dataloader),"-- epoch", epoch+1, "/", num_epoch, "---- Loss_D : ", loss_D.item(), " Loss_G : ", loss_G.item(),
            " D(x) : ", D_x, " D(G(z1)) : ", D_G_z1, " D(G(z2)) : ", D_G_z2)
      
      #print(outputD2)

      #print(fake.size())

      #print(noise)
      #print(fake)

      #note : fake.size() = torch.Size([128,1,64,64])
      #note : data[0].size() = torch.Size([128,3,64,64])
      #note : fake[0,:,:,:].size() = torch.Size([1,64,64])
      #note : data[0][0,:,:,:].size() = torch.Size([3,64,64])

    if epoch%5==0 and i == 0:

      plt.figure(figsize=(14,14))
      plt.axis("off")
      plt.title("Training Images a l'époque "+str(epoch)+" et à l'itération "+str(i))
      plt.imshow(np.transpose(vutils.make_grid(fake.to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))
      plt.show()


    if epoch > num_epoch - 2 :
      for i in range(fake.size()[0]) :
        compteur+=1
        to_cpu = fake.to(device='cpu')
        to_numpy = to_cpu.detach().numpy()
            #print(to_numpy.shape) #(128, 1, 64, 64)
            #print(to_numpy[i][0].shape) #(64, 64)
        plt.gray()
        plt.imsave("/content/fake_generated/fake_"+str(compteur)+".png", to_numpy[i][0]) #on fait attention à convertir en numpy
      



plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_loss_l,label="G")
plt.plot(D_loss_l,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()

